[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggtern, plotly)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plot-a-static-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plot-a-static-ternary-diagram",
    "title": "Hands-on_Ex05",
    "section": "Plot a static ternary diagram",
    "text": "Plot a static ternary diagram\n\nUsing ggtern() function\n\nggtern(data=agpop_mutate,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plot-an-interactive-ternary-diagram",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#plot-an-interactive-ternary-diagram",
    "title": "Hands-on_Ex05",
    "section": "Plot an interactive ternary diagram",
    "text": "Plot an interactive ternary diagram\n\nUsing plot_ly() function\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutate, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed. If they are, they will be launched into R.\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel)\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: ggrepel: 317 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\n\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\np1 + p2 / p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n((p1/p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot)\n\n\n\n\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\nRows: 6497 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): type\ndbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\npairs() method\n\npairs(wine[,1:11])\n\n\n\n\nggcormat() method\nonly correlation variables are needed (column 1 to 11)\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\nGive more aesthetic argument and Control visual attributes: font size, X-Axis and Y-Axis\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         tl.cex =10),\n  title = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n)\n\n\n\nggplot.component = list(\n  theme(text = element_text(size = 5),\n        axis.text.x = element_text(size = 8),\n        axis.text.y = element_text(size = 8)))\n\n\n\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\ncorrplot() package\nUsing cor() of R Stats to compute the correlation matrix of wine data frame\n\nwine.cor <- cor(wine[,1:11])\ncorrplot(wine.cor)\n\n\n\n\nChange visual geometrics\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor,\n               lower = \"ellipse\",\n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nwine.sig = cor.mtest(wine.cor, conf.level = 0.95)\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "title": "Hands-on_Ex05_2",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse, GGally, parallelPlot)\n\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nChange row number by country name\n\nrow.names(wh) <- wh$Country\n\nWarning: Setting row names on a tibble is deprecated.\n\n\nTransform data frame into matrix\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\nHeatmap() of R Stats\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nPlot a cluster heatmap\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\nNormalise matric column-wise\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\nThere are a few ways to transform the data.\nThere are scaling method, normalising method and percentage method\n\nheatmaply(wh_matrix[,-c(1,2,4,5)],\n          scale = \"column\")\n\nWarning in doTryCatch(return(expr), name, parentenv, handler): unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':\n  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 0x0006): Library not loaded: '/opt/X11/lib/libSM.6.dylib'\n  Referenced from: '/Library/Frameworks/R.framework/Versions/4.2/Resources/modules/R_X11.so'\n  Reason: tried: '/opt/X11/lib/libSM.6.dylib' (no such file), '/Library/Frameworks/R.framework/Resources/lib/libSM.6.dylib' (no such file), '/Library/Java/JavaVirtualMachines/jdk1.8.0_241.jdk/Contents/Home/jre/lib/server/libSM.6.dylib' (no such file)\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[,-c(1,2,4,5)]))\n\n\n\n\n\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\nFurther spread out\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on_Ex07",
    "section": "",
    "text": "Load the code chunk to check whether the following packages has been installed.\n\n# sf is the updated version of sp\npacman::p_load(sf, tmap, tidyverse)\n\n\n\nThe code chunk below uses the st_read() function of sf package to import shapefile into R as a simple feature data frame called mpsz\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/HG-YN/ISSS608-VAA/Hands-on_Ex/Hands-on_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on_Ex08",
    "section": "",
    "text": "Load the code chunk to check whether the following packages has been installed.\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\nSentDate is in character format, we will convert into DMY field.\nAlso create Weekday column to be in the day of the week format.\nThe below is done using lubridate() package.\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SentDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\nFocus on “work related” email and group by the sender and recipients.\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on_Ex08",
    "section": "Creating network objects using tidygraph",
    "text": "Creating network objects using tidygraph\nUse tbl_graph() of tidygraph package to build the network graph\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# … with 48 more rows\n#\n# Edge Data: 1,456 × 4\n   from    to Weekday   Weight\n  <int> <int> <ord>      <int>\n1     1     2 Monday         4\n2     1     2 Tuesday        3\n3     1     2 Wednesday      5\n# … with 1,453 more rows\n\n\nThe output shows 1372 edges and 54 nodes.\n\nChange the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest \"weight\" first, we could use activate() and then arrange().\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,456 × 4 (active)\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1    40    41 Tuesday     23\n2    40    43 Tuesday     19\n3    41    43 Tuesday     15\n4    41    40 Tuesday     14\n5    42    41 Tuesday     13\n6    42    40 Tuesday     12\n# … with 1,450 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# … with 51 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plot-network-data-with-ggraph",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#plot-network-data-with-ggraph",
    "title": "Hands-on_Ex08",
    "section": "Plot Network data with ggraph",
    "text": "Plot Network data with ggraph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\nWork on the aesthetics\n\ng <- ggraph(GAStech_graph) +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nChanging colors\n\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\nUsing Fruchterman and Reingold Layout\n\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nModifying network nodes\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nModifying edges\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#work-on-facet-graph-based-on-edges-and-nodes-individually",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#work-on-facet-graph-based-on-edges-and-nodes-individually",
    "title": "Hands-on_Ex08",
    "section": "Work on facet graph based on edges and nodes individually",
    "text": "Work on facet graph based on edges and nodes individually\n\nFacet_edges()\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\nChange the position of the legend using theme()\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\nAdd frame to each graph with th_foreground() function\n\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\nWorking with facet_nodes()\nBased on department information\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#network-metrics-analysis",
    "title": "Hands-on_Ex08",
    "section": "Network Metrics Analysis",
    "text": "Network Metrics Analysis\n\nComputing centrality indices\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1456 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# … with 48 more rows\n#\n# Edge Data: 1,456 × 4\n   from    to Weekday   Weight\n  <int> <int> <ord>      <int>\n1     1     2 Monday         4\n2     1     2 Tuesday        3\n3     1     2 Wednesday      5\n# … with 1,453 more rows"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on_Ex08",
    "section": "Building Interactive Network Graph with visNetwork",
    "text": "Building Interactive Network Graph with visNetwork\nData preparation\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\nBuild the interactive network graph\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nWork on the visual attributes\n\nNodes\nWe can color the nodes according department\n\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nEdges\nFrom visEdges(), we place arrows and smooth the curve\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nInteractivity\nvisOptions() is used to allow selection by id (names)\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started\n::: callout-info ## Do It Yourself Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\nShow the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmetically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nNote: ymd_hms() and hour() are from lubridate package and weekdays() is a base R function.\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: Beside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk: - a tibble data table called grouped is derived by aggregating the attack by wkday and hour fields. - a new field called n is derived by using group_by() and count() functions. - na.omit() is used to exclude missing value. - geom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles. - theme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot. - coord_equal() is used to ensure the plot will have an aspect ratio of 1:1. - scale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Cycle Plot",
    "text": "Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Load the code chunk to check whether the following packages has been installed\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#cycle-plot",
    "title": "Hands-on Exercise 6",
    "section": "Cycle Plot",
    "text": "Cycle Plot\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on_Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed. If they are, they will be launched into R.\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Application. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/takehome_1.html",
    "href": "Take-home_Ex/Take-home_Ex01/takehome_1.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "In this Take Home Exercise, we aim to analyse the demographic structure of Singapore at planning area level by building an age-sex pyramid trellis chart.\nThe dataset used is downloaded from the following link:\nhttps://www.singstat.gov.sg/find-data/search-by-theme/population/geographic-distribution/latest-data\n\n1. Step-by-Step Description\n\n\n\n\n\n\n\n\nstep\naction\nimage\n\n\n\n\n1\nOpen Tableau Desktop, and load the downloaded file into Tableau using Text file.\nOnce the raw dataset is loaded, drag the Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022 csv file into Tableau Desktop.\n\n\n\n2\nTabulate Female population. We created a calculated field for female population.\nWrite a formula based on Population containing “female” word under “Sex” category to extract female population.\n\n\n\n3\nTabulate Male population. We created a calculated field for male population.\nWrite a formula based on Population containing “male” word under “Sex” category to extract male population.\n\n\n\n4\nCreate the Matrix for trellis display (3 * 3 for 9 Planning Areas). We created a calculated field for Row calculation, and convert it to discrete.\n\n\n\n5\nWe created a calculated field for Column calculation, and convert it to discrete.\n\n\n\n6\nCreate Age Group from AG. Combine each two adjacent age group for easier display.\n\n\n\n7\nDrag Female Pop and Male Pop to Columns field. Edit Axis of Female Pop to be reverse.\n\n\n\n8\nDrag AG(group) to Rows. Sort AG(group) in descending order.\n\n\n\n9\nDrag PA into Filters and select 9 most populated planning areas.\nWe select the 9 most populated planning areas by opening another worksheet. Drag Pop into Columns and PA into Rows. Sort Pop in descending orders. From this chart, it’s clearly seen that the top 9 most populated planning areas are: Bedok, Tampines, Jurong West, Sengkang, Woodlands, Hougang, Yishun, Choa Chu Kang, and Puggol.\nDelete this worksheet after obtaining the planning area information. We filter the selected 9 PA in the original worksheet.\n\n\n\n10\nDrag PA into Details under Marks Tab\n\n\n\n11\nDrag Column to Columns. Row to Rows.\nEdit the Table Calculation for both Row and Column. Change to “Compute using Specific Dimensions” and select PA. Choose “At the level” to be PA.\nDo the same for Column.\n\n\n\n12\nHide the Row and Column axis by unchecking the Show Header.\n\n\n\n13\nUnder Marks Female Pop, change the color of female population tab to be pink. That of male population to be blue.\n\n\n\n14\nDrag Female Pop into Label of SUM(Female Pop) and Male Pop into Label of SUM(Male Pop).\n\n\n\n15\nEdit Axis of x axis (Female Pop and Male Pop). Choose Fixed range to be 0 to 35K.\nThis is to make sure all population share x axis of the same range.\n\n\n\n16\nCreate a new Dashboard. Drag the worksheet into the dashboard area.\n\n\n\n17\nAdd text box to show the different planning areas. Choose black color to improve on visual contrast and locate them to be on top right hand corner of each sub plot.\n\n\n\n\n\n\n2. Major Observations\nWe have selected the most populated 9 planning areas in Singapore based on SingStat data dated in June 2022, namely: Bedok, Tampines, Jurong West, Sengkang, Woodlands, Hougang, Yishun, Choa Chu Kang, and Puggol, for visual analysis. These 9 planning areas are chosen as we can observe the population pyramid shape more clearly.\n\nSimilarities observed among all planning areas:\n\nThe population pyramid in these 9 planning areas of Singapore exhibit a “constrictive” population pyramid shape, with a relatively narrow base and a wide middle portion. There are lower number of young people (age group 0 to 19) compared to middle-aged people (age group 30 to 49), implying a low fertility rate in general.\nThere is a broad shape at top, showing a high life expectancy in Singapore, with a high proportion of elderly population(age group 70 and above). There is a higher number of female elderly population compared to male elderly population across all planning groups, indicating that usually female has a longer life expectancy than male.\nMale and female population are similar across all planning areas, indicating a good gender equality in Singapore.\nThese most populated planning areas all fall under Outside Central Region and are residential areas. The low residential accommodation price, and abundance of residential properties may lead to high population in these areas.\n\n\nDifferences observed among planning areas:\n\nThere is a narrowing base observed in Bedok, Jurong West, Woodlands, Hougang and Choa Chu Kang. This indicates a falling birth rate in these planning areas. Whereas in the other 4 planning areas, there are more population under 0-9 age group, indicating that the birth rate has improved. The most significant increase in fertility is observed in Punggol. It could lead to more nursery and schools demands in Punggol area.\nThere are differences in bulges observed in different planning areas. For example, there are significant bulges observed in Punggol and Sengkang area for population under age group 30 to 49. This could be due to residents relocation to Punggol and Sengkang for work purpose. While Bulges for Bedok are observed in 50 to 69 age group population. This may suggest that Bedok is good for retirement.\nThere are differences in indents observed in different planning areas. For example, there are significant indents observed in Woodlands for 30 to 49 age group population. While indents for Punggol happens significantly for 20 to 29 age group population. This could be due to residence relocation due to education, work or other reasons.\nTop 3 planning areas with the most number of elderly (age group 70 and above) are Bedok, Tampines and Hougang. While in terms of total population, the top 3 planning areas are Bedok, Tampines and Jurong West. Hougang ranks number 6 in total population. This suggests that Hougang has a relatively higher proportion of elderly population. Elderly facilities would be in needed in Hougang area.\n\nThe above concludes the take home exercise 1. Thank you for reading!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html",
    "title": "Take-Home_Ex04",
    "section": "",
    "text": "In this Take-Home Exercise 4, we are using Merchandise Trade by Region/Market provided by Department of Statistics, Singapore (DOS) to study the impact of COVID-19 as well as the global economic and political dynamic in 2022 on Singapore bi-lateral trade.\nFirstly, we load the code chunk to check whether the following packages has been installed.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, plotly,data.table, readxl, lubridate, stringr, dplyr, gganimate, transformr, patchwork, sunburstR, d3r)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#load-the-data",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#load-the-data",
    "title": "Take-Home_Ex04",
    "section": "Load the Data",
    "text": "Load the Data\nWe have downloaded the Merchandise Trade by Region/Market data from DOS and name it as outputFile.xlsx. This data file consists merchandise import and export by region/market monthly.\nWe import outputFile.xlsx file into R environment, called the data frame as import and export and select the relevant rows by using read_excel() function.\n\nimport <- read_excel(\"data/outputFile.xlsx\", sheet = \"T1\", range = \"A10:AL129\")\nexport <- read_excel(\"data/outputFile.xlsx\", sheet = \"T2\", range = \"A10:AL101\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-preparation",
    "title": "Take-Home_Ex04",
    "section": "Data Preparation",
    "text": "Data Preparation\nThere are 3 types of data in the import and output data frame:\n\nTrade by Continent (in Millions)\nTrade by Country (in Thousands)\nTotal Merchandise Trade (in Thousands)\n\nHence we will create separate data frame for these 3 types of trade data for separate analysis.\nWe will filter the data for the relevant time period (January 2020 to December 2022)\n\nImport -ContinentExport -Continent\n\n\nFor Import Trade by Continents (Million Dollars)\n\n\nCode\nimport_continent <- import[2:7, ]%>%\n    select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nimport_continent$Country <- gsub(\"\\\\s*\\\\(.*?\\\\)\", \"\", import_continent$Country)\n\n\n\n\nFor Export Trade by Continents (Million Dollars)\n\n\nCode\nexport_continent <- export[2:7, ]%>%\n    select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nexport_continent$Country <- gsub(\"\\\\s*\\\\(.*?\\\\)\", \"\", export_continent$Country)\n\n\n\n\n\n\nImport -CountryExport -Country\n\n\nFor Import Trade by Countries (Thousand Dollars)\n\n\nCode\nimport_country <- import[8:119, ]%>%\n    select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nimport_country$Country <- gsub(\"\\\\s*\\\\(.*?\\\\)\", \"\", import_country$Country)\n\n\n\n\nFor Export Trade Countries (Thousand Dollars)\n\n\nCode\nexport_country <- export[8:91, ]%>%\n    select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nexport_country$Country <- gsub(\"\\\\s*\\\\(.*?\\\\)\", \"\", export_country$Country)\n\n\n\n\n\n\nImport -TotalExport -Total\n\n\nFor Total Import Trade (Thousand Dollars)\n\n\nCode\nimport_total <- import[1, ]%>%\n    select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nimport_total$Country <- gsub(\"\\\\s*\\\\(.*?\\\\)\", \"\", import_total$Country)\n\n\n\n\nFor Total Export Trade (Thousand Dollars)\n\n\nCode\nexport_total <- export[1, ]%>%\n    select(`Data Series`, contains(c(\"2020\", \"2021\", \"2022\"))) %>%\n  set_names(if_else(names(.) == \"Data Series\", \"Country\", names(.)))\n\nexport_total$Country <- gsub(\"\\\\s*\\\\(.*?\\\\)\", \"\", export_total$Country)\n\n\n\n\n\n\nClean and transform data\nNext we will reshape the data into long format with Country, Month-Year and Value as column names.\nWe will also format Month-Year into data format using as.Date() function for graph plotting.\n\nContinentCountryTotal\n\n\n\n\nCode\ncontinent_i <- reshape2::melt(import_continent, id.vars = \"Country\", \n                                   variable.name = \"Month-Year\", value.name = \"Value\", \n                                   na.rm = TRUE)\ncontinent_i$`Month-Year` <- as.Date(paste(continent_i$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\ncontinent_e <- reshape2::melt(export_continent, id.vars = \"Country\", \n                                   variable.name = \"Month-Year\", value.name = \"Value\", \n                                   na.rm = TRUE)\ncontinent_e$`Month-Year` <- as.Date(paste(continent_e$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\n\n\n\n\n\nCode\ncountry_i <- reshape2::melt(import_country, id.vars = \"Country\", \n                                   variable.name = \"Month-Year\", value.name = \"Value\", \n                                   na.rm = TRUE)\ncountry_i$`Month-Year` <- as.Date(paste(country_i$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\n\ncountry_e <- reshape2::melt(export_country, id.vars = \"Country\", \n                                   variable.name = \"Month-Year\", value.name = \"Value\", \n                                   na.rm = TRUE)\ncountry_e$`Month-Year` <- as.Date(paste(country_e$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\n\n\n\n\n\nCode\ntotal_i <- reshape2::melt(import_total, id.vars = \"Country\", \n                                   variable.name = \"Month-Year\", value.name = \"Value\", \n                                   na.rm = TRUE)\ntotal_i$`Month-Year` <- as.Date(paste(total_i$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\ntotal_e <- reshape2::melt(export_total, id.vars = \"Country\", variable.name = \"Month-Year\",\n                          value.name = \"Value\",  na.rm = TRUE)\ntotal_e$`Month-Year` <- as.Date(paste(total_e$`Month-Year`, \"01\"), format = \"%Y %b %d\")\n\n\n\n\n\n\n\nMerge Data Frame\nAs now the import and export data are separate for continent, country and total trade, we will merge them by using merge() function. We will also create a new column Net to calculate the balance of trade (BOT = Export -Import).\nAfter the import and export data are merged into trade data, we will use pivot_longer() function to reshape the data into long format and also indicate whether the trade is import or export in an column named Variable.\n\nContinentCountryTotal\n\n\n\n\nCode\ncontinent_trade <- merge(x=continent_i , y=continent_e, by= c(\"Country\", \"Month-Year\"), all.x = TRUE, all.y = TRUE)\ncontinent_trade <- continent_trade%>%\n  rename(Import = Value.x, Export = Value.y) %>%\n  mutate(Net = Export - Import)\n\ncontinent_trade_long <- continent_trade %>%\n  pivot_longer(cols = c(\"Import\", \"Export\"), names_to = \"Variable\", values_to = \"Value\")\n\n\n\n\n\n\nCode\ncountry_trade <- merge(x=country_i , y=country_e, by= c(\"Country\", \"Month-Year\"), na.rm = TRUE)\ncountry_trade <- country_trade%>%\n  rename(Import = Value.x, Export = Value.y) %>%\n  mutate(Net = Export - Import)\n\ncountry_trade_long <- country_trade %>%\n  pivot_longer(cols = c(\"Import\", \"Export\"), names_to = \"Variable\", values_to = \"Value\")\n\n\n\n\n\n\nCode\ntotal_trade <- bind_rows(total_i %>% mutate(Data = \"Total Import\"),\n                            total_e %>% mutate(Data = \"Total Export\"))\n\n\n\n\n\n\n\nOverview of Cleaned Data\nNow we have the cleaned data. We will use head() function to have an overview.\n\nhead(continent_trade_long)\n\n# A tibble: 6 × 5\n  Country `Month-Year`   Net Variable Value\n  <chr>   <date>       <dbl> <chr>    <dbl>\n1 Africa  2020-01-01    193. Import    529.\n2 Africa  2020-01-01    193. Export    722.\n3 Africa  2020-02-01    175. Import    666.\n4 Africa  2020-02-01    175. Export    841 \n5 Africa  2020-03-01    357. Import    559.\n6 Africa  2020-03-01    357. Export    916.\n\n\n\nhead(country_trade_long)\n\n# A tibble: 6 × 5\n  Country     `Month-Year`   Net Variable Value\n  <chr>       <date>       <dbl> <chr>    <dbl>\n1 Afghanistan 2020-01-01    3599 Import       7\n2 Afghanistan 2020-01-01    3599 Export    3606\n3 Afghanistan 2020-02-01    2133 Import      66\n4 Afghanistan 2020-02-01    2133 Export    2199\n5 Afghanistan 2020-03-01    5287 Import       6\n6 Afghanistan 2020-03-01    5287 Export    5293\n\n\n\nhead(total_trade)\n\n                    Country Month-Year    Value         Data\n1 Total Merchandise Imports 2020-12-01 40154550 Total Import\n2 Total Merchandise Imports 2020-11-01 38477878 Total Import\n3 Total Merchandise Imports 2020-10-01 38173829 Total Import\n4 Total Merchandise Imports 2020-09-01 38801413 Total Import\n5 Total Merchandise Imports 2020-08-01 36472279 Total Import\n6 Total Merchandise Imports 2020-07-01 37843646 Total Import"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-exploration-and-data-visualization",
    "href": "Take-home_Ex/Take-home_Ex04/Take-home_Ex04.html#data-exploration-and-data-visualization",
    "title": "Take-Home_Ex04",
    "section": "Data Exploration and Data Visualization",
    "text": "Data Exploration and Data Visualization\n\n1. Total Trade over Time\nFirstly, let us look at total trade over time in Singapore to understand the general trend for import and export, and also the impact of Covid19 to Singapore trade in general.\n\nLine Chart for Total Import and Export from 2020 to 2022\nPlot a line graph to show total Import and Export Trade Value over time.\n\np1 <- ggplot(data = total_trade,\n       aes(x = `Month-Year`,\n           y = `Value`)) +\n  geom_line(aes(colour = `Data`)) +\n  labs(title = \"Singapore Total Import and Export from 2020 to 2022\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\nggplotly(p1)\n\n\n\n\n\nObservation\nIn general, there is an upward trend for both import and export in Singapore over time.\nThe total export is higher than the total import throughout all year. This indicates a positive balance of trade in Singapore with an active foreign market.\nEven though there are some impact on trade volume due to Covid19, for example, a dip in export and import from Mar to May 2020 due to Circuit Breaker (CB) in Singapore, the overall trend and trend volume is not heavily affected due to pandemic situation.\n\n\n\n2. Trade by Continent over Time\nAfter understanding the general trend for total import and export in Singapore, we will dive into import and export by continent from 2020 to 2022.\n\nInteractive Stacked Bar Chart for Import and Export by Continent from 2020 to 2022\nAs there are import and export for each continent, we will plot a stacked bar graph to visualize total trade volume by continent. We will also use ggplotly() to introduce interactivity to the plot. This will help us to see different continent trade performance over time at one glance.\n\np2 <- ggplot(continent_trade_long, aes(x = `Month-Year`, y = `Value`, fill = Variable, \n                                       text = paste(\"Variable: \", Variable))) +\n      geom_col() +\n      facet_wrap(~ Country, ncol = 2) +\n      scale_fill_manual(values = c(\"salmon\", \"lightblue\")) +\n      labs(title = \"Import and Export Values Over Time by Continent\",\n           x = \"Month-Year\", y = \"Value\", fill = \"\") +\n      theme_minimal()\n\nggplotly(p2)\n\n\n\n\n\nObservation\nFrom the stacked bar chart, we observe that Asia contributes the most in terms of export and import to Singapore market. It remains as the top trading continent partner with Singapore across time.\nFollowing Asia, America and Europe Continent come in as second and third, followed by European Union, Oceania and Africa. The trade volume for America, Europe and European Union are similar.\n\n\nAnimated Time Series Scatter Plot of Trade by Continent\nPlot an animated scatter plot to show import and export values for different continents over time\n\np3 <- ggplot(continent_trade, aes(x = Import, y = Export, size = Net, color = Country)) +\n  geom_point(alpha = 0.7) +\n  scale_color_manual(values = rainbow(length(unique(continent_trade$Country)))) +\n  scale_size_continuous(range = c(1, 10)) +\n  labs(title = \"Import and Export Values Over Time\",\n       x = \"Import\", y = \"Export\", size = \"Net\") +\n  transition_states(`Month-Year`) +\n  ease_aes('linear')\n\nanimate(p3, fps = 10, duration = 10, width = 800, height = 600)\n\n\n\n\nObservation\nFrom the animation time series scatter plot, we can observe the trade pattern change for each continent over time. Asia has the most significant fluctuation in terms of import and export volume and ratio, whereas Africa has the least fluctuation.\nAmerica is usually the second place in Import and Export in trade volume, but is overtaken by Europe in some months.\n\n\n\n3. Trade by Country over Time\nAfter understanding the different continent trading patterns, now we look at trade patterns by country from 2020 to 2022.\nFrom the data, we have over 80 countries and regions in total. Hence it will be difficult to use general charts such as line, bar or scatter plot to visualize the data. Hence we will explore Sunburst chart to visualize the proportion of Singapore’s import and export trade with different countries/ regions.\nThis chart shows multiple rings, with each ring representing a different level of the hierarchy. The innermost ring will represent the total amount of import or export, while the outer rings will represent the different countries/ regions with which Singapore trades. The size of each segment will represent the proportion of Singapore’s trade with that trading partner.\n\nInteractive Sunburst Chart of Trade by Country from 2020 to 2022\n\ncountry_hier <- country_trade_long %>%\n  group_by(Variable, Country) %>%\n  summarize(totalAmount = sum(`Value`))\n\ncountry_sunburst <- d3_nest(country_hier, value_cols = \"totalAmount\")\n\nsunburst(data = country_sunburst,\n         valueField = \"totalAmount\",\n         height = 300,\n         width = \"100%\",\n         legend = FALSE) \n\n\n\n\n\n\n\n\n\n\nLegend\n\n\n\n\n\n\n\nObservation\nThis visualization can help to identify the countries that are most important for Singapore’s import and export trade byy looking at the size of each segment.\nFor import, there are 4 important trading partners: Mainland China, Malaysia, Taiwan and United States, all contributing more than 5% of Singapore import volume.\nFor export, the top 3 trading partners are Mainland China, Hong Kong and Malaysia, all contributing more than 5% of Singapore export volume. The United States comes in at 4th place at 4.98%.\nMainland China is the top trading partner for both import and export in Singapore. Hence it is important to study the trading pattern of Mainland China as its variation will impact Singapore economy significantly.\n\n\nCycle Plot for Mainland China\n\nchina_trade_long <- subset(country_trade_long, Country == \"Mainland China\")\n\nchina_trade_long$`Month-Year` <- as.Date(as.character(china_trade_long$`Month-Year`), format = \"%Y-%m-%d\")\n\np4 <- ggplot(china_trade_long, aes(x = `Month-Year`, y = `Value`, group = Variable, color = Variable)) + \n  geom_line() +\n  scale_x_date(limits = c(min(china_trade_long$`Month-Year`), max(china_trade_long$`Month-Year`))) + \n  labs(x = \"Month-Year\", y = \"Value\", title = \"Import and Export Value for Mainland China\") +\n  theme(axis.text.x = element_text( size =8))\n\np4 %>% \n  ggplotly() %>% \n  layout(hovermode = \"x unified\") %>% \n  add_annotations(xref = \"paper\", yref = \"paper\", x = 0.5, y = -0.15,\n                  text = \"\",\n                  showarrow = FALSE, font = list(size = 14))\n\n\n\n\n\nObservation\nImport and Export volume with Mainland China and Singapore has some fluctuations over time. There are several significant dips in Feb 2020, Feb 2021 and Feb 2022. This could be due to Chinese New Year long holiday and short month in Feburary, causing a significant dip in trade volume.\nFrom Jul 2020 to Apr 2022, there is in general a positive trade of balance with China with more export than import (except in Jan/Feb 2021). However, the import from China has been picking up rapidly since Feb 2022. This could be due to pandemic situation as Mainland China has a lock-down policy."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home_Ex03",
    "section": "",
    "text": "In this take-home exercise, we will look into the patterns of the resale prices of public housing property by residential towns and estates in Singapore."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#install-and-launching-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#install-and-launching-r-packages",
    "title": "Take-home_Ex03",
    "section": "Install and launching R packages",
    "text": "Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if the necessary packages are installed. If they are, they will be launched into R.\n\npacman::p_load(tidyverse, dplyr, ggplot2,ggstatsplot, performance, plotly, crosstalk, DT, ggdist, gganimate,FunnelPlotR, knitr)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "title": "Take-home_Ex03",
    "section": "Importing the data",
    "text": "Importing the data\nThe code chunk below uses read_csv function to reads the CSV file into a data frame named property_data.\nThe dataset: Resale flat princes based on registration date from Jan-2017 onwards.\nData is from Data.gov.sg.\n\nproperty_data <- read_csv(\"data/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-exploration-and-analytical-visualisation-selection",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-exploration-and-analytical-visualisation-selection",
    "title": "Take-home_Ex03",
    "section": "Data Exploration and Analytical Visualisation Selection",
    "text": "Data Exploration and Analytical Visualisation Selection\nFirstly, we will need to understand the data attributes in the selected data set:\n\n\n\nData Attributes\nData Type\n\n\n\n\nmonth\ndatetime\n\n\ntown\ntext\n\n\nflat type\ntext\n\n\nblock\ntext\n\n\nstreet name\ntext\n\n\nstorey range\ntext\n\n\nfloor area sqm\nnumeric\n\n\nflat model\ntext\n\n\nlease commence date\ndatetime\n\n\nremaining lease\ntext\n\n\nresale price\nnumeric\n\n\n\nWe can also run summary() to get a glance of the data set.\n\nsummary(property_data)\n\n    month               town            flat_type            block          \n Length:146429      Length:146429      Length:146429      Length:146429     \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n street_name        storey_range       floor_area_sqm    flat_model       \n Length:146429      Length:146429      Min.   : 31.00   Length:146429     \n Class :character   Class :character   1st Qu.: 82.00   Class :character  \n Mode  :character   Mode  :character   Median : 94.00   Mode  :character  \n                                       Mean   : 97.61                     \n                                       3rd Qu.:113.00                     \n                                       Max.   :249.00                     \n lease_commence_date remaining_lease     resale_price    \n Min.   :1966        Length:146429      Min.   : 140000  \n 1st Qu.:1985        Class :character   1st Qu.: 358000  \n Median :1996        Mode  :character   Median : 448000  \n Mean   :1996                           Mean   : 478124  \n 3rd Qu.:2007                           3rd Qu.: 565000  \n Max.   :2019                           Max.   :1418000  \n\n\nIn this take-home exercise, we will focus on 3, 4, 5 Room HDB in the study period of 2022.\nIn order to explore the patterns of the resale prices of public housing property by residential towns and estates in Singapore, there are a few possible affecting factors we can analyse, namely: town, flat type, floor area sqm, flat model and lease commence date/ remaining lease.\nHence from the above, some consideration of the visualization analysis are:\n\nLook into the resale price by 2 different flat midels. We choose standard and DBSS in this exercise. We can build a Two-Sample-Mean-Test to do the comparison.\nThen we can focus on standard HDB flat model to do a fair comparison on how other factors affect the resale price. We firstly look at Resale price by town as location is one of the most important factor. We will firstly create a bar chart to show average resale price by town. Then we will do an uncertainty of point estimate to understand the reliability and accuracy of the estimates generated.\nThen we start to explore resale price by floor area sqm. We use a scatter plot to visualise the pattern distribution first. Then we conduct a significant test of correlation to understand on their correlation relationship.\nAs there are a few possible affecting factors, namely: town, flat type, floor area sqm and lease commence date/ remaining lease, we will run a multiple regression model with these factors against resale price to see which factor(s) has/ have higher correlation.\nThen we look at flat type (3, 4 or 5 Room HDB) and resale price by using box plot\nLastly we build a heatmap"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#analytical-visualisation-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#analytical-visualisation-preparation",
    "title": "Take-home_Ex03",
    "section": "Analytical Visualisation Preparation",
    "text": "Analytical Visualisation Preparation\n\nData preparation\nWe use filter function from dplyr() package to extract rows that satisfy the given criteria.\n\nextracts rows where the first four characters of “month” column are “2022” to make 2022 as the study period\nextract “flat_type” column whereby is “3 Room” ,“4 Room” or “5 Room”.\nextract “flat_model” column to be “Standard” or “DBSS” HDB.\nThe resulting filtered data is stored in a new data frame named filtered_data\n\n\nfiltered_data <- property_data %>%\n  filter(substr(month, 1, 4) == \"2022\", flat_type %in% c(\"3 ROOM\", \"4 ROOM\",\"5 ROOM\"), flat_model %in% c(\"Standard\",\"DBSS\") )\n\nAs the flat_type is in text format, we extract numeric part of flat_type column using mutate() in order to use it for chart plotting.\n\nfiltered_data <- filtered_data %>% mutate(flat_type_num = str_extract(flat_type, \"\\\\d+\"))\n\n\n\nFlat Model (Standard VS DBSS) Resale Price Comparison with Two-sample Mean Test\nAs DBSS flats are built by private developers with each development characterised by unique external features, it is usually a preferred choice for potential buyers. Hence we would like to compare it’s resale price compared to standard HDB via two-sample mean test, and understand roughly how much premium is required for DBSS flat.\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of resale price by flat model, namely DBSS and Standard.\n\nggbetweenstats(\n  data = filtered_data,\n  x = flat_model, \n  y = resale_price,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nPattern Observation\nWe can observe from the above chart, DBSS flat resale price mean is at 758K, compared to that of standard HDB at 405K. There are fewer transactions of DBSS in 2022 (in total 395) compared to standard (in total 657). This could be due to more standard HDB flats in the market.\n\n\nResale Price by Town\nAs now we know that there is a significant difference in resale price between DBSS and Standard HDB, we will narrow down the scope to Standard flat model in order to reduce the number of variables. This will help us to understand the relationship between resale price with other affecting factors, such as town, sqm and flat type better.\nHence, we create another tibble data, standard_data for Standard HDB flat model.\n\nstandard_data <- filtered_data %>%\n  filter(flat_model == (\"Standard\") )\n\n\n\nAverage Resale Price by Town\nUse a geom_bar() in ggplot() package to plot a simple bar chart to compare the average resale price of different towns.\nUse plotly() to add interactivity to show town name and average resale price of the selected town.\n\nbar_chart <- ggplot(standard_data, aes(x = town, y = resale_price)) +\n  geom_bar(stat = \"summary\", fun = \"mean\") +\n  labs(x = \"Town\", y = \"Average Resale Price\") +\n  theme(axis.text.x=element_blank(),\n        axis.ticks.x=element_blank()) +\n  ggtitle(\"Average Resale Price by Town\")\n\nbar_chart <- ggplotly(bar_chart, tooltip = c(\"town\", \"resale_price\"))\n\nbar_chart\n\n\n\n\n\nPattern Observation\nFrom the bar chart, we can observe that the top 3 town based on average resale price are: Bukit Timah, Marine Parade and Clementi. The bottom 3 are: Geylang, Toa Payoh and Kallang/ Whampoa.\nBefore jumping into conclusion, it is also important to conduct a Uncertainty Test for resale price.\n\n\nVisualizing the Uncertainty of Point Estimates\nWe create another tibble data, my_sum, to calculate the mean, standard deviation and standard error of resale price in standard_data.\n\nmy_sum <- standard_data %>%\n  group_by(town) %>%\n  summarise(\n    n=n(),\n    mean=mean(resale_price),\n    sd=sd(resale_price)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nThen we use geom_errorbar() function from ggplot() package. We are able to visualise clearly the resale price standard error and the mean resale price indicated by a red dot for different town.\nThen convert it to a plotly object using ggplotly() function.\n\nerrorbar_plot <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x=town, \n        ymin=mean-se, \n        ymax=mean+se)) +\n  xlab(\"town\") +\n  ylab(\"resale price standard error with mean\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank()) +\n    geom_point(aes\n           (x=town, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 0.5,\n           alpha=1) +\n  facet_wrap(~ town) +\n  ggtitle(\"Standard Error of Mean Resale Price by Town\")\n\np_interactive <- ggplotly(errorbar_plot)\n\np_interactive\n\n\n\n\n\nPattern Observation\nThe above uncertainty of point estimates trellis chart show the range of resale price that the estimate is likely to fall within, with 95% level of confidence.\nWe can see that the variability in resale price in Clementi is the largest. Whereas in towns such as Bedok, Hougang, Jurong West and Woodlands, there is not much variability in the mean resale price. This will lead to easier price prediction in these regions.\n\n\nResale Price by Floor Area in Different Towns\nAfter understanding the differences in average resale prices in various towns, we now add floor area (sqm) into consideration. We look at individual transaction resale price rather than average for this case.\nWe use geom_point() from ggplot2 package to create a scatter plot to explore the relationship between resale price and floor area, with different colors or shapes representing different towns or estates.\n\nscatter_plot <- ggplot(standard_data, aes(x = floor_area_sqm, y = resale_price, color = town)) +\n  geom_point() +\n  labs(x = \"Floor Area (sqm)\", y = \"Resale Price\", color = \"Town\") +\n  ggtitle(\"Scatter plot of Resale Price vs. Floor Area by Town\")\n\nscatter_plot <- ggplotly(scatter_plot, tooltip = c(\"town\",\"floor_area_sqm\", \"resale_price\"))\n\nscatter_plot\n\n\n\n\n\nPattern Observation\nWe observe that even though Bukit Timah has the highest average resale price, the top 3 resale price transactions are for HDB in Maria Parade.\nThe common assumption is the bigger the floor area, the higher the resale price. In order to understand more about the correlation between floor area sqm and resale price, we will run a Significant Test of Correlation.\n\n\nSignificant Test of Correlation\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between floor area (sqm) and resale price (S$).\n\nggscatterstats(\n  data = standard_data,\n  x = floor_area_sqm,\n  y = resale_price,\n  marginal = FALSE,\n  )\n\n\n\n\nPattern Observation\nFrom the above t-test with sample size of 657 transactions, we see a linear correlation between floor area (sqm) VS resale price. The correlation coefficient, r(pearson) = 0.87, indicating a positive linear relationship between floor area (sqm) and resale price. The small p value indicates statistic significance.\nHowever, there are still outliers which fall far away from the linear regression line.\nHence we will continue the exploration by looking into Multiple regression model to consider other factors.\n\n\nMultiple Regression Model\nWe will add in lease commence date and flat type into the model and build a multiple regression model. This is to analyse how these other factors affecting the resale price besides floor area.\n\nmodel <- lm(resale_price ~ floor_area_sqm + lease_commence_date + flat_type_num, data = standard_data)\n\nsummary(model)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + lease_commence_date + \n    flat_type_num, data = standard_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-370302  -48060   -5561   45874  367167 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         5268643.6  3192415.2   1.650   0.0994 .  \nfloor_area_sqm        11242.0      685.1  16.410  < 2e-16 ***\nlease_commence_date   -2854.3     1624.3  -1.757   0.0793 .  \nflat_type_num4       -57666.9    35704.0  -1.615   0.1068    \nflat_type_num5      -290137.3    40508.0  -7.162 2.15e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 100300 on 652 degrees of freedom\nMultiple R-squared:  0.7751,    Adjusted R-squared:  0.7737 \nF-statistic: 561.8 on 4 and 652 DF,  p-value: < 2.2e-16\n\n\nPattern Observation\nFrom the small p-value, we know that at least one of the factors are affecting the resale price significantly. The R-squared value, 0.7737 shows a generally good fit of the model. But before concluding whether this is a good regression model, we will need to check for multicolinearity.\n\n\nModel Diagnostic: Checking for Multicolinearity\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n           Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n floor_area_sqm 27.06 [23.34, 31.40]         5.20      0.04     [0.03, 0.04]\n\nHigh Correlation\n\n                Term   VIF     VIF 95% CI Increased SE Tolerance\n lease_commence_date  3.00   [2.65, 3.41]         1.73      0.33\n       flat_type_num 26.49 [22.85, 30.74]         5.15      0.04\n Tolerance 95% CI\n     [0.29, 0.38]\n     [0.03, 0.04]\n\n\nPattern Observation\nFrom the Multicollinearity check, we know that floor area sqm is a good predictor variable as it has a low correlation. However, the lease commence date and flat type have high correlation. Hence we might need to analyse them separately.\n\n\nResale Price Distribution by Flat Type in Different Towns\nWe use geom_boxplot() under ggplot() package to create a box plot.\nThis helps in visualising the distribution of resale prices for different flat types and towns.\n\nbox_plot <- ggplot(standard_data, aes(x = flat_type, y = resale_price)) +\n  geom_boxplot() +\n  labs(x = \"Flat Type\", y = \"Resale Price\") +\n  ggtitle(\"Resale Price Distribution by Flat Type\")\n\nbox_plot <- ggplotly(box_plot, tooltip = \"resale_price\")\n\nbox_plot\n\n\n\n\n\nPattern Observation\nGenerally, the average resale price is highest for 5 Room, followed by 4 Room and 3 Room.\nThere are the most number of outliers for 3 Room flat resale prices, meaning some transaction of 3 Room flat sell at very high prices.\nThe resale prices for 4 Room flat are closely distributed, the variability is the smallest.\nThe resale price range for 5 Room flat are the biggest.\n\n\nHeatmap Visualization on Resale Price, Floor Area sqm and Lease Commence Date\nWith all the above analysis, now we want to build a heatmap to visualize at a glance.\nWe use geom_tile() from ggplot() to plot a heatmap to visualize between different variables, such as resale price, floor area, and lease commence date/ year.\n\nheatmap <- ggplot(standard_data, aes(x = factor(lease_commence_date), y = factor(floor_area_sqm), fill = resale_price)) +\n  geom_tile() +\n  labs(x = \"Lease Commence Year\", y = \"Floor Area (sqm)\", fill = \"Resale Price\") +\n  ggtitle(\"Heatmap of Correlation between Resale Price, Floor Area, and Year\")\n\nggsave(\"heatmap.png\", heatmap, height = 8, units = \"in\")\n\n\nPattern Observation\nWe can see when taking lease commence year and floor area, generally the newer the flat (later lease commence year) and bigger the size (bigger floor area), the higher the resale price (lighter in blue color tone). However there are also some outliers.\nHence it is really not enough to look at one aspect of the HDB property to predict the price, all these factors: town, flat type, floor area sqm, flat model and lease commence date/ remaining lease, play a part in influencing the resale price.\nThe above concludes my Take Home Exercise 3.\nThank you for reading!"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "In this take-home exercise, we will look at one of classmates population pyramid chart and evaluate it in terms of clarity and aesthetics. We will also re-make the original chart design by using ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-and-launching-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#install-and-launching-r-packages",
    "title": "Take Home Exercise 2",
    "section": "Install and launching R packages",
    "text": "Install and launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed. If they are, they will be launched into R.\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel,ggiraph)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-the-data",
    "title": "Take Home Exercise 2",
    "section": "Importing the data",
    "text": "Importing the data\nThe code chunk below uses read_csv function to import the dataset: Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022, into R and name it ppltn_data for future reference.\n\nppltn_data <- read_csv(\"data/respopagesextod2022.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(ppltn_data)\n\n# A tibble: 6 × 7\n  PA         SZ                     AG     Sex   TOD                   Pop  Time\n  <chr>      <chr>                  <chr>  <chr> <chr>               <dbl> <dbl>\n1 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 1- and 2-Room …     0  2022\n2 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 3-Room Flats       10  2022\n3 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 4-Room Flats       10  2022\n4 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HDB 5-Room and Exe…    30  2022\n5 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males HUDC Flats (exclud…     0  2022\n6 Ang Mo Kio Ang Mo Kio Town Centre 0_to_4 Males Condominiums and O…    50  2022"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#clarity",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#clarity",
    "title": "Take Home Exercise 2",
    "section": "2.1 Clarity",
    "text": "2.1 Clarity\n\na) Dashboard Title\nFor easy understanding of the graph, title should serve as a clear summary of the graph. The current dashboard title –“Different demographic patterns are revealed when Singapore population pyramids are grouped by planning areas”, is more like a factual description rather than a summary of the graph presented.\n\n\nb) Graph Title\nAs graph title is under the dashboard title, it is unclear to audience in terms of which one to pay attention to. We can combine the dashboard and graph title as there is only one trellis chart in the dashboard.\n\n\nc) Data Label\nIn the original chart, only 2 or 3 sets of data are labelled in each population pyramid graph. It is unclear to audience why these sets of data are labelled or emphasized. We can label only the minimum and maximum set for more distinct comparison, or using interactive method to eliminate the label but allow audience to be able to read the details when the cursor is hovering above the interested bar."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetics",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aesthetics",
    "title": "Take Home Exercise 2",
    "section": "2.2 Aesthetics",
    "text": "2.2 Aesthetics\n\na) Color Intensity Tone\nAs population pyramid has shown the population absolute number in terms of vertical bar length, color intensity is not necessary to show population. Hence we can remove the color intensity to make the graph look cleaner.\n\n\nb) Axes Label\nThe Y axis label –age group, has been split into 19 categories in total (0 to 4 till 90 and over). It is visually too dense to see clearly. More gap should be introduced in between each age group label.\n\n\nc) Title\nIt is more visually pleasant to make graph title center aligned instead of left aligned."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#sketch-of-proposed-design",
    "title": "Take Home Exercise 2",
    "section": "3.1 Sketch of Proposed Design",
    "text": "3.1 Sketch of Proposed Design"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "Take Home Exercise 2",
    "section": "3.2 Data Wrangling",
    "text": "3.2 Data Wrangling\nFirstly we use filter() function to select the planning areas that the original chart has used.\n\nfiltered_PA <- ppltn_data %>%\n  filter(`PA` ==\"Ang Mo Kio\" |\n           `PA` ==\"Bedok\" |\n           `PA`== \"Choa Chu Kang\" |\n           `PA`== \"Jurong West\" |\n           `PA`== \"Pasir Ris\" |\n           `PA`== \"Punggol\" |\n           `PA`== \"Sembawang\" |\n           `PA`== \"Tampines\" |\n           `PA`== \"Toa Payoh\")\n\nThen we will compute Singapore population by planning areas, gender and age using group_by() function.\nWe calculate the female and male population based on different age groups for the selected planning areas and put into a column named “Count”.\n\nfiltered_population <- filtered_PA %>%\n  group_by(AG,PA,Sex) %>%\n  summarise('Count'= sum(`Pop`), .groups = 'drop')\n\nSecondly, we sort the data based on age group and in ascending order by using mutate() and arrange() function. This is to sort the age group based on ascending order, rather than alphabetical order.\n\nage <- c(\"0_to_4\", \"5_to_9\", \"10_to_14\", \"15_to_19\", \"20_to_24\", \"25_to_29\", \"30_to_34\", \"35_to_39\", \"40_to_44\", \"45_to_49\", \"50_to_54\", \"55_to_59\", \"60_to_64\", \"65_to_69\", \"70_to_74\", \"75_to_79\", \"80_to_84\", \"85_to_89\", \"90_and_over\")\n\npopulation <- filtered_population %>%\n  mutate(AG =  factor(AG, levels = age)) %>%\n  arrange(AG)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-design",
    "title": "Take Home Exercise 2",
    "section": "3.3 Final Design",
    "text": "3.3 Final Design\nWe have prepared data. Now we are going to plot a trellis chart of population pyramid using ggplot() and facet_wrap() function.\nFirstly we set the male population to be on the -X axis and female population to be on X axis.\nWe use geo_col_interactive() function to introduce tooltip interactivity to the chart, and also eliminate population number labeling to make the chart more aesthetically appealing.\nThen we set the chart labels and captions using labs(), as well as the font size under theme().\nLastly we mark the female and male population in different colors with scale_fill_manual() function.\n\nstatic_plot <- ggplot(population, aes(x = ifelse(Sex == \"Males\", yes = -Count, no = Count), \n                            y = AG, fill = Sex)) + \n  geom_col_interactive(\n    aes(tooltip= paste0(Sex,\"(\",AG,\")\",\" : \",Count))) +\n  facet_wrap(~ PA) +\n  labs (x = \"Population\", \n        y = \"Age Group\", \n        title='Singapore Age-Sex Population Pyramid by Planning Area',\n        caption = \"Source: Department of Statistics Singapore, 2022\") +\n  xlim(-13000,13000) +\n  theme(axis.text = element_text(size = 5),\n        plot.title = element_text(size = 10),\n        plot.caption = element_text(size = 5)) +\n  theme(axis.ticks.y = element_blank()) +\n  scale_fill_manual(values = c(\"Males\" = \"steelblue\", \"Females\" = \"darksalmon\"))\n\nknitr::opts_chunk$set(fig.width=30, fig.height=30) \n\nstatic_plot\n\n\n\n\nIn order to make the group easy to read and also able to zoom-in for details, we will use girafe() to creative interactive plot.\nWe set the width and height to make the y axis age group label easy to read.\n\ngirafe(\n  ggobj = static_plot,\n  width_svg = 6,\n  height_svg = 6)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03.html",
    "href": "In-Class_Ex/In-Class_Ex03.html",
    "title": "In-Class_Ex03",
    "section": "",
    "text": "Installing and loading R packages\nTwo packages will be installed and loaded: tidyverse and ggiraph.\n\npacman::p_load(ggiraph,tidyverse, plotly)\n\nImport data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\nshow_col_types = FALSE\n\nggplot2\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 10,\n                 boundary = 100,\n                 color=\"black\",\n                 fill=\"grey\") +\n  ggtitle(\"Distribution of maths scores\")\n\n\n\n\nDot Plot\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\nVisual Interactivity with girafe\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6 * 0.618\n)\n\n\n\n\n\nTo display multiple information on tooltip\n\nexam_data$tooltip <- c(paste0(     #<<\n  \"Name = \", exam_data$ID,         #<<\n  \"\\n Class = \", exam_data$CLASS)) #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), #<<\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nCustomize tooltip: change background and font.\n\ntooltip_css <- \"background-color:white; #<<\nfont-style:bold; color:black;\" #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #<<\n    opts_tooltip(    #<<\n      css = tooltip_css)) #<<\n)                                        \n\n\n\n\n\nTo add in statistics on tooltip\nWe write in function and pass mean, standard error, and paste them onto the plot.\n\ntooltip <- function(y, ymax, accuracy = .01) {   #<<\n  mean <- scales::number(y, accuracy = accuracy) #<<\n  sem <- scales::number(ymax - y, accuracy = accuracy) #<<\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem) #<<\n} #<<\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #<<\n                     tooltip(y, ymax))),  #<<\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #<<\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nUsing data_id() to show clusters\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #<<\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nWe use hover effect\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        #<<\n    opts_hover(css = \"fill: #202020;\"),  #<<\n    opts_hover_inv(css = \"opacity:0.2;\") #<<\n  )                                      #<<  \n)                                        \n\n\n\n\n\nCombine the tooltip and hover effect\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, #<<\n        data_id = CLASS),#<<              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nUsing onclick()\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              #<<\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nTry Plotly()\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\nUse plotly() color mapping\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) #<<\n\n\n\n\n\nChange color pallete\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = \"Set1\") #<<"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04.html",
    "href": "In-Class_Ex/In-Class_Ex04.html",
    "title": "In-Class_Ex04",
    "section": "",
    "text": "Getting Started\nLoad the packages\n\npacman::p_load(ggiraph,tidyverse, plotly, DT, ggplotly, patchwork,ggstatsplot, ggside)\n\nData\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\nshow_col_types = FALSE\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH,\n             color = ~RACE, \n             colors = \"Set1\")\n\n\n\n\n\nInteractive scatter plot\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #<<\n\n\n\n\n\nCombine multiple plots with subplot()\n\np1 <- ggplot(data=exam_data, \n              aes(x = MATHS,\n                  y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),            #<<\n        ggplotly(p2))            #<<\n\n\n\n\n\n\n\nVisual Statistics Analysis with ggstatsplot\nOne Sample test with gghistostats()\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nTwo sample mean test using ggbetweenstats()\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nSignificant Test of Correlation\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  )\n\n\n\n\n\n\nVisualising Models\nLoad additional packages\n\npacman::p_load(readxl, performance, parameters, see)\n\nRead the data file this time using read_xls(_)\nRead the data tab/ worksheet in the Excel file.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\nBuild a multiple linear regression model using lm() of Base Stats of R\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\nDiagnostic Test of Model\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\nVisualise the multicollinearity report\n(<5 no multi-collinearity; >=10: high multi-collinearity)\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\nCheck normality assumption using check_normality() from performance package\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\ncheck_n <- check_normality(model1)\nplot(check_n)\n\n\n\n\nCheck model for homogeneity of variances\n\ncheck_h <- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\nComplete check model diagnostic\n\ncheck_model(model1)\n\n\n\n\nVisualising regression parameters\n\nplot(parameters(model1))\n\n\n\n\nUsing ggcoefstats() from ggstatsplot package\n\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\n\n\nVisualizing the uncertainty\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate)\nexam <- read_csv(\"data/Exam_data.csv\")\n\nUsing ggplot2 to save the output as a tibble data\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\nThen visualise standard error of mean maths score by race\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")"
  }
]